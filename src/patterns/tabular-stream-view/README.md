# Tabular Stream View Pattern

## Overview

The Tabular Stream View pattern enables progressive rendering of structured tabular data as it streams in from an AI/LLM. Users can interact with partial results (sorting, filtering, exporting) before the complete dataset arrives, providing immediate utility and reducing perceived latency.

**Demo Scenario**: StreamFlow PM's AI assistant analyzes team capacity for Q1 2025 planning. The AI streams team member data progressively (names, roles, skills, availability, rates), showing each row as it's computed. Product managers can start exploring capacity even before all team members are analyzed.

---

## Intent

**Teach developers how to:**
- Render tabular data progressively as rows stream in
- Implement client-side operations (sort/filter) on partial datasets
- Show skeleton loaders for anticipated rows based on schema hints
- Provide CSV export functionality that works during streaming
- Maintain type safety with structured stream events
- Integrate network inspection for stream transparency

**When to use this pattern:**
- Displaying structured data computed by LLMs (tables, lists, matrices)
- Large result sets where early partial data is useful
- Reports or analytics generated by AI agents
- Scenarios where users need to explore data before completion

**Compared to other patterns:**
- **Chain-of-Reasoning**: Shows unstructured thinking steps; Tabular shows structured data
- **Agent-Await-Prompt**: Pauses for user input; Tabular streams continuously
- **Multi-Turn Memory Timeline**: Tracks conversation state; Tabular shows single-turn data

---

## Architecture: How the UI "Calls the Backend"

### Complete Data Flow

```
┌─────────────────────────────────────────────────────────────────┐
│                  TabularStreamViewDemo.tsx                      │
│                                                                 │
│  const { schema, rows, metadata, isStreaming } =                │
│    useTabularStream({ scenario, speed, onEvent })              │
│                           ↓                                     │
└───────────────────────────┼─────────────────────────────────────┘
                            │
                            │ 1. Call hook with config
                            ↓
┌─────────────────────────────────────────────────────────────────┐
│                          hooks.ts                               │
│                   useTabularStream()                            │
│                                                                 │
│  useEffect(() => {                                              │
│    const stream = createMockTabularStream(config)               │
│                           ↓                                     │
└───────────────────────────┼─────────────────────────────────────┘
                            │
                            │ 2. Create AsyncGenerator
                            ↓
┌─────────────────────────────────────────────────────────────────┐
│                      mockStream.ts                              │
│              createMockTabularStream()                          │
│                                                                 │
│  async function* createMockTabularStream() {                    │
│    const fixture = getFixture(scenario)                         │
│    for (const event of fixture) {                               │
│      await delay(delayMs)        // Simulate network latency    │
│      onEvent(event)              // → Network Inspector         │
│      yield event                 // ← Send to hook              │
│    }                             ↓                              │
└───────────────────────────┼─────────────────────────────────────┘
                            │
                            │ 3. Yield events: schema → rows → metadata
                            ↓
┌─────────────────────────────────────────────────────────────────┐
│                          hooks.ts                               │
│                   useTabularStream()                            │
│                                                                 │
│    for await (const event of stream) {                          │
│      switch (event.type) {                                      │
│        case 'schema':                                           │
│          setSchema(event.data)                                  │
│        case 'table_row':                                        │
│          setRows(prev => [...prev, event.data])                 │
│        case 'table_meta':                                       │
│          setMetadata(event.data)                                │
│          setIsComplete(true)    ↓                               │
└───────────────────────────┼─────────────────────────────────────┘
                            │
                            │ 4. Update state → Trigger re-render
                            ↓
┌─────────────────────────────────────────────────────────────────┐
│                  TabularStreamViewDemo.tsx                      │
│                                                                 │
│  // Component re-renders with new state                         │
│  <StreamingTable schema={schema} rows={visibleRows} />         │
│  <CompletionFooter metadata={metadata} isComplete={isComplete}/>│
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Step-by-Step Explanation

### Step 1: UI Component Calls the Hook

**File**: `TabularStreamViewDemo.tsx` (lines 122-149)

```tsx
// The UI component calls useTabularStream with configuration
const {
  schema,             // ← State: Table structure (columns, types, aggregations)
  rows,              // ← State: Array of row data (grows progressively)
  metadata,          // ← State: Completion metadata with aggregations
  isStreaming,       // ← State: Whether stream is active
  isComplete,        // ← State: Whether stream has finished
  error,             // ← State: Any stream errors
  sort,              // ← State: Current sort configuration
  filters,           // ← State: Active filters
  setSort,           // ← Function: Update sort order
  addFilter,         // ← Function: Add/update a filter
  removeFilter,      // ← Function: Remove a filter
  clearFilters,      // ← Function: Clear all filters
  getVisibleRows,    // ← Function: Get filtered/sorted rows
  exportCSV          // ← Function: Export data as CSV
} = useTabularStream({
  scenario: 'team-capacity',      // Which fixture to use
  speed,                           // Stream speed (fast/normal/slow)
  onEvent: (event) => {            // Callback for network inspector
    captureEvent(adaptEventForNetworkInspector(event));
  }
});
```

**What happens**: The component declares what state and operations it needs. React will re-render whenever state changes.

---

### Step 2: Hook Creates the Mock Stream

**File**: `hooks.ts` (lines 214-229)

```tsx
// Inside the useEffect, create an async generator stream
const stream = createMockTabularStream(config);

// Then consume it with for-await-of loop
for await (const event of stream) {
  // Check if cancelled
  if (!isMountedRef.current || cancelledRef.current) {
    break;
  }

  // Process event based on type
  switch (event.type) {
    case 'schema': setSchema(event.data); break;
    case 'table_row': setRows(prev => [...prev, event.data]); break;
    case 'table_meta':
      setMetadata(event.data);
      setIsComplete(true);
      break;
  }
}
```

**What happens**: The hook instantiates an AsyncGenerator (the "backend connection") and consumes events in a loop.

---

### Step 3: Mock Stream Yields Events

**File**: `mockStream.ts` (lines 42-83)

```tsx
export async function* createMockTabularStream(
  config: TabularStreamConfig = {}
): AsyncGenerator<StreamEvent, void, undefined> {
  // Get fixture data for the scenario
  const fixture = getFixture(config.scenario || 'default');

  // Determine delay based on speed
  const delayMs = SPEED_DELAYS[config.speed || 'normal'];

  // Yield each event from fixture with delay
  for (const event of fixture) {
    // Simulate network latency
    await delay(delayMs);

    // Call event callback for Network Inspector
    if (config.onEvent) {
      config.onEvent(event);  // ← Sends to Network Inspector
    }

    // Yield event to consumer (the hook)
    yield event;  // ← This is where the "backend response" comes through
  }
}
```

**What happens**:
- Generator pulls events from fixture data (schema, 12 rows, metadata)
- Adds delay (50ms-1000ms) to simulate network latency
- Calls `onEvent` to send events to Network Inspector
- **Yields** event back to the hook (pauses until next `.next()` call)

**Fixture structure** (`fixtures.ts`):
```typescript
[
  { type: 'schema', data: { title, columns, totalRows, metadata } },
  { type: 'table_row', data: { rowId: 'dev-001', values: {...}, timestamp } },
  { type: 'table_row', data: { rowId: 'dev-002', values: {...}, timestamp } },
  // ... 10 more rows ...
  { type: 'table_meta', data: { totalRows, aggregations, completedAt, metadata } }
]
```

---

### Step 4: Hook Processes Events

**File**: `hooks.ts` (lines 238-251)

```tsx
// Process event based on type
switch (event.type) {
  case 'schema':
    // Set table structure (columns, types, aggregation functions)
    setSchema(event.data);  // ← Triggers re-render, shows table headers
    break;

  case 'table_row':
    // Add row to the array (this triggers re-render!)
    setRows((prevRows) => [...prevRows, event.data]);  // ← Progressive row rendering
    break;

  case 'table_meta':
    // Set completion metadata with aggregations
    setMetadata(event.data);  // ← Triggers re-render, shows footer
    setIsComplete(true);
    break;
}
```

**What happens**:
- Each `yield` from mock becomes an event here
- Hook calls `setSchema()`, `setRows()`, or `setMetadata()` which **triggers React re-render**
- Table progressively grows as each row event arrives

---

### Step 5: UI Re-renders with New State

**File**: `TabularStreamViewDemo.tsx` (lines 270-278)

```tsx
// When state updates, React schedules a re-render
<StreamingTable
  schema={schema}            // ← Table structure
  rows={visibleRows}         // ← Current rows (filtered/sorted)
  isStreaming={isStreaming}  // ← Show loading indicator
  isComplete={isComplete}    // ← Hide skeleton rows when done
  sort={sort}                // ← Show sort indicators
  onSort={handleHeaderSort}  // ← Handle column clicks
/>
```

**What happens**:
- Every time `setSchema()` or `setRows()` is called, React re-renders
- StreamingTable component reads updated state and displays it
- Skeleton rows appear for anticipated data (based on `schema.totalRows`)
- This creates the "streaming" visual effect: rows appear one by one

---

## Stream Contract

### Event Types

```typescript
// Schema event (first event, defines table structure)
interface SchemaEvent {
  type: 'schema';
  data: {
    title: string;                  // Table title (e.g., "Team Capacity Matrix")
    columns: ColumnDefinition[];    // Array of column definitions
    totalRows?: number;             // Hint for skeleton row count
    metadata?: Record<string, unknown>; // Additional context
  };
}

// Column definition
interface ColumnDefinition {
  id: string;                       // Column ID (e.g., "name", "role")
  label: string;                    // Display label
  type: 'string' | 'number' | 'boolean' | 'date';  // Data type
  sortable: boolean;                // Whether column supports sorting
  filterable: boolean;              // Whether column supports filtering
  unit?: string;                    // Unit prefix (e.g., "$", "%", "hrs")
  aggregation?: 'sum' | 'avg' | 'min' | 'max' | 'count';  // How to aggregate
  width?: string;                   // CSS width
}

// Row event (progressive data)
interface TableRowEvent {
  type: 'table_row';
  data: {
    rowId: string;                  // Unique row identifier
    values: Record<string, string | number | boolean | null>;  // Column values
    timestamp: number;              // When row was generated
  };
}

// Metadata event (final event, includes aggregations)
interface TableMetaEvent {
  type: 'table_meta';
  data: {
    totalRows: number;              // Total number of rows sent
    aggregations?: Record<string, number>;  // Aggregated values (sum, avg, etc.)
    completedAt: number;            // Completion timestamp
    metadata?: Record<string, unknown>;  // Additional summary data
  };
}

type StreamEvent = SchemaEvent | TableRowEvent | TableMetaEvent;
```

### Stream Lifecycle

```
START
  ↓
  ├─ schema event (defines structure, columns, types)
  ↓
  ├─ table_row event (row 1)
  ├─ table_row event (row 2)
  ├─ table_row event (row 3)
  ├─ ... (progressive rows)
  ├─ table_row event (row N)
  ↓
  ├─ table_meta event (completion + aggregations)
  ↓
END
```

**Key Design Decision**: Schema comes first so the UI can render table headers and skeleton rows before any data arrives. This provides immediate visual feedback.

---

## UX Flow

### User Experience Timeline

1. **Initial Load** (0ms)
   - User triggers AI action (e.g., "Analyze team capacity")
   - UI shows loading indicator

2. **Schema Arrival** (~50-300ms)
   - Table headers appear
   - Skeleton rows appear (based on `totalRows` hint)
   - User sees table structure immediately

3. **Progressive Row Streaming** (~300-3000ms)
   - Rows appear one by one, replacing skeleton rows
   - User can start interacting: sorting, filtering, scrolling
   - Streaming indicator shows progress: "Streaming data... (5 of 12 rows)"

4. **Client-Side Operations** (during streaming)
   - User clicks column header → table sorts by that column
   - User adds filter → table re-filters visible rows
   - User clicks "Export CSV" → exports partial data

5. **Stream Completion** (~3000ms+)
   - Last row appears
   - Completion footer shows with aggregated statistics
   - Streaming indicator disappears
   - Export button now includes complete dataset

### Progressive Enhancement

**What users can do BEFORE stream completes:**
- View partial results
- Sort by any column
- Filter rows
- Export CSV (partial data)
- Scroll through received data

**What becomes available AFTER stream completes:**
- Aggregated statistics (totals, averages)
- Complete dataset export
- Full confidence in data accuracy

---

## UI Techniques

### 1. Progressive Table Rendering

**Implementation**: `StreamingTable.tsx`

- **Skeleton Rows**: Show anticipated data before it arrives
  ```tsx
  const skeletonRowCount = Math.max(0, schema.totalRows - rows.length);
  {Array.from({ length: skeletonRowCount }).map((_, index) => (
    <SkeletonRow key={`skeleton-${index}`} columnCount={schema.columns.length} />
  ))}
  ```

- **Streaming Indicator**: Show progress to user
  ```tsx
  {isStreaming && (
    <div className={styles.streamingIndicator}>
      <span className={styles.spinner} />
      <span>Streaming data... ({rows.length} of {schema.totalRows || '?'} rows)</span>
    </div>
  )}
  ```

- **Type-Safe Cell Rendering**: Format cells based on column type
  ```tsx
  function formatCellValue(value: string | number | boolean | null, column: ColumnDefinition) {
    switch (column.type) {
      case 'number': return column.unit ? `${column.unit}${value}` : value;
      case 'boolean': return value ? 'Yes' : 'No';
      case 'date': return new Date(value).toLocaleDateString();
      default: return String(value);
    }
  }
  ```

### 2. Client-Side Sorting

**Implementation**: `hooks.ts` (lines 325-346)

- Sort operates on whatever rows have arrived so far
- Clicking column header cycles through: none → asc → desc → none
- Sort indicator shows current state: ⇅ (none), ↑ (asc), ↓ (desc)

```tsx
function getVisibleRows(): TableRow[] {
  let visibleRows = [...rows];

  // Apply sorting
  if (sort && sort.direction) {
    visibleRows.sort((a, b) => {
      const aValue = a.values[sort.columnId];
      const bValue = b.values[sort.columnId];
      return compareValues(aValue, bValue, sort.direction === 'asc');
    });
  }

  return visibleRows;
}
```

### 3. Client-Side Filtering

**Implementation**: `hooks.ts` (lines 328-334)

- Filters work on partial data (whatever has arrived)
- Multiple filters use AND logic (row must match ALL filters)
- Supports operators: equals, contains, gt, lt, gte, lte

```tsx
// Apply filters
if (filters.length > 0) {
  visibleRows = visibleRows.filter((row) => {
    return filters.every((filter) => applyFilter(row, filter));
  });
}
```

### 4. CSV Export

**Implementation**: `hooks.ts` (lines 104-129, 354-357)

- Works at any time (before or after stream completes)
- Exports currently visible rows (respects filters and sort)
- Handles special characters (commas, quotes) properly

```tsx
function rowsToCSV(schema: TableSchema | undefined, rows: TableRow[]): string {
  if (!schema || rows.length === 0) return '';

  // Create header row
  const headers = schema.columns.map((col) => col.label).join(',');

  // Create data rows with proper escaping
  const dataRows = rows.map((row) => {
    return schema.columns
      .map((col) => {
        const value = row.values[col.id];
        if (value === null || value === undefined) return '';
        const stringValue = String(value);
        // Escape commas and quotes
        if (stringValue.includes(',') || stringValue.includes('"')) {
          return `"${stringValue.replace(/"/g, '""')}"`;
        }
        return stringValue;
      })
      .join(',');
  });

  return [headers, ...dataRows].join('\n');
}
```

### 5. Completion Footer with Aggregations

**Implementation**: `CompletionFooter.tsx`

- Only appears when stream completes
- Shows aggregated statistics defined in schema (sum, avg, min, max)
- Displays row counts (filtered vs. total)
- Provides final export button

```tsx
{hasAggregations && metadata.aggregations && (
  <div className={styles.aggregationsSection}>
    <div className={styles.aggregationsTitle}>Summary Statistics</div>
    {Object.entries(metadata.aggregations).map(([columnId, value]) => (
      <div key={columnId} className={styles.aggregation}>
        <span>{getAggregationLabel(columnId, schema)}:</span>
        <span>{formatAggregation(value, columnId, schema)}</span>
      </div>
    ))}
  </div>
)}
```

---

## Server Notes (Mock Implementation)

### Fixture Structure

**File**: `fixtures.ts`

All mock data is deterministic and version-controlled:

```typescript
// 1. Schema defines structure
export const teamCapacitySchema: TableSchema = {
  title: 'Team Capacity Matrix - Q1 2025',
  columns: [
    { id: 'name', label: 'Team Member', type: 'string', sortable: true },
    { id: 'role', label: 'Role', type: 'string', sortable: true, filterable: true },
    { id: 'allocation', label: 'Current Allocation', type: 'number', unit: '%', aggregation: 'avg' },
    // ... more columns
  ],
  totalRows: 12  // ← Hint for skeleton rows
};

// 2. Row data (12 team members)
export const teamCapacityRows: TableRow[] = [
  {
    rowId: 'dev-001',
    values: {
      name: 'Sarah Chen',
      role: 'Senior Frontend Engineer',
      skills: 'React, TypeScript, CSS, Accessibility',
      allocation: 85,
      availableHours: 6,
      hourlyRate: 125,
      availableFrom: '2025-01-06',
      isRemote: true
    },
    timestamp: Date.now()
  },
  // ... 11 more rows
];

// 3. Metadata with aggregations
export const teamCapacityMetadata: TableMetadata = {
  totalRows: 12,
  aggregations: {
    allocation: 79.58,      // Average allocation
    availableHours: 98,     // Total available hours
    hourlyRate: 114.17      // Average rate
  },
  completedAt: Date.now(),
  metadata: {
    totalCost: 11320,        // Custom aggregation
    fullyAllocated: 2,
    availableNow: 6
  }
};
```

### Speed Configuration

```typescript
const SPEED_DELAYS: Record<DemoSpeed, number> = {
  fast: 50,      // 50ms per row (600ms total for 12 rows)
  normal: 300,   // 300ms per row (3.6s total)
  slow: 1000     // 1s per row (12s total)
};
```

### Real Backend Integration

To connect to a real streaming API:

1. **Replace `createMockTabularStream` with real fetch**:
   ```tsx
   async function* createRealTabularStream(config) {
     const response = await fetch('/api/team-capacity', {
       method: 'POST',
       body: JSON.stringify(config)
     });

     const reader = response.body.getReader();
     const decoder = new TextDecoder();

     while (true) {
       const { done, value } = await reader.read();
       if (done) break;

       const chunk = decoder.decode(value);
       const events = chunk.split('\n\n').filter(Boolean);

       for (const eventStr of events) {
         const event = JSON.parse(eventStr.replace('data: ', ''));
         yield event;
       }
     }
   }
   ```

2. **Update hook to use real stream**:
   ```tsx
   const stream = config.useRealAPI
     ? createRealTabularStream(config)
     : createMockTabularStream(config);
   ```

---

## Instrumentation (Network Inspector Integration)

### Event Capture

**File**: `TabularStreamViewDemo.tsx` (lines 39-96)

The pattern adapts internal events to the global event schema for Network Inspector:

```tsx
function adaptEventForNetworkInspector(event: PatternStreamEvent): GlobalStreamEvent | null {
  switch (event.type) {
    case 'schema':
      return {
        type: 'schema',
        data: {
          id: event.data.title || 'table-schema',
          name: event.data.title,
          columns: event.data.columns.map(col => ({
            id: col.id,
            name: col.label,
            type: col.type,
            required: false
          })),
          description: event.data.title
        }
      };

    case 'table_row':
      return {
        type: 'table_row',
        data: {
          id: event.data.rowId,
          data: event.data.values,
          timestamp: event.data.timestamp
        }
      };

    case 'table_meta':
      return {
        type: 'table_meta',
        data: {
          totalRows: event.data.totalRows,
          progress: 1.0,
          isComplete: true
        }
      };
  }
}
```

### Integration Flow

```typescript
const { captureEvent } = useNetworkCapture();

const tabularStream = useTabularStream({
  scenario: 'team-capacity',
  speed,
  onEvent: (event) => {
    // Adapt and capture event for inspector
    const globalEvent = adaptEventForNetworkInspector(event);
    if (globalEvent) {
      captureEvent(globalEvent);  // ← Sent to Network Inspector
    }
  }
});
```

**What Network Inspector shows:**
- Schema event with column definitions
- 12 individual row events with full data
- Metadata event with aggregations
- Timestamps for performance analysis

---

## File Structure

```
tabular-stream-view/
├── TabularStreamViewDemo.tsx          # Main demo component
├── TabularStreamViewDemo.module.css   # Demo styles
├── TabularStreamViewDemo.test.tsx     # Integration tests
├── StreamingTable.tsx                 # Table component with progressive rendering
├── StreamingTable.module.css          # Table styles
├── TableControls.tsx                  # Sort/filter controls
├── TableControls.module.css           # Controls styles
├── CompletionFooter.tsx               # Aggregations and export
├── CompletionFooter.module.css        # Footer styles
├── hooks.ts                           # useTabularStream hook
├── mockStream.ts                      # AsyncGenerator mock
├── fixtures.ts                        # Mock team capacity data
├── types.ts                           # TypeScript interfaces
└── README.md                          # This file
```

---

## Usage Example

### Basic Usage

```tsx
import { useTabularStream } from './hooks';
import { StreamingTable } from './StreamingTable';

function TeamCapacityTable() {
  const { schema, rows, isStreaming, getVisibleRows } = useTabularStream({
    scenario: 'team-capacity',
    speed: 'normal'
  });

  const visibleRows = getVisibleRows();

  return (
    <StreamingTable
      schema={schema}
      rows={visibleRows}
      isStreaming={isStreaming}
      isComplete={false}
      sort={null}
    />
  );
}
```

### With Sorting and Filtering

```tsx
function AdvancedTable() {
  const {
    schema,
    rows,
    sort,
    filters,
    setSort,
    addFilter,
    getVisibleRows
  } = useTabularStream({ scenario: 'team-capacity' });

  const visibleRows = getVisibleRows();

  return (
    <>
      <TableControls
        schema={schema}
        sort={sort}
        filters={filters}
        onSortChange={setSort}
        onFilterAdd={addFilter}
      />
      <StreamingTable
        schema={schema}
        rows={visibleRows}
        isStreaming={false}
        isComplete={true}
        sort={sort}
        onSort={(columnId) => setSort({ columnId, direction: 'asc' })}
      />
    </>
  );
}
```

### With CSV Export

```tsx
function ExportableTable() {
  const { schema, rows, isComplete, exportCSV, getVisibleRows } = useTabularStream({
    scenario: 'team-capacity'
  });

  const handleExport = () => {
    const csv = exportCSV();
    console.log('Exported CSV:', csv);
    // Download logic here
  };

  return (
    <>
      <StreamingTable schema={schema} rows={getVisibleRows()} />
      {isComplete && <button onClick={handleExport}>Export CSV</button>}
    </>
  );
}
```

---

## Running the Demo

```bash
# Start dev server
npm run dev

# Navigate to:
# http://localhost:5173/patterns/tabular-stream-view

# Run tests
npm test src/patterns/tabular-stream-view

# Run tests with coverage
npm test src/patterns/tabular-stream-view -- --coverage
```

---

## Design Decisions

### Why Schema-First?

**Schema event arrives before any rows** because:
1. UI can render table headers immediately (perceived performance)
2. Skeleton rows need column count (better loading UX)
3. Client knows data types for formatting (type safety)
4. Sort/filter controls can be shown early (progressive enhancement)

### Why Client-Side Sort/Filter?

**Operations happen on the client** (not server) because:
1. **Immediate feedback**: No network round-trip for sorting
2. **Partial data utility**: Users can explore before completion
3. **Reduced server load**: No additional API calls
4. **Offline-capable**: Works without server connection
5. **Educational value**: Shows frontend data manipulation

**Trade-off**: Large datasets (1000+ rows) may need server-side pagination.

### Why Skeleton Rows?

**Skeleton loaders for anticipated rows** provide:
1. **Perceived performance**: Table feels faster
2. **Layout stability**: No content shift as rows arrive
3. **Progress indication**: Visual feedback on remaining data
4. **Professional UX**: Modern, polished appearance

**Implementation**: `totalRows` hint in schema event enables accurate skeleton count.

### Why Progressive Over Batch?

**Streaming row-by-row** instead of batching because:
1. **Lower latency**: First row appears faster
2. **Better UX**: Continuous progress vs. jarring updates
3. **Educational focus**: Teaching streaming patterns
4. **Resource efficiency**: Incremental rendering (no large batch re-render)

**Real-world consideration**: Batching (e.g., 10 rows at once) may be better for very high-frequency streams.

---

## Performance Considerations

### Memory Management

- **Cleanup on unmount**: `cancelledRef` stops stream consumption
- **Mounted check**: `isMountedRef` prevents state updates after unmount
- **Generator cleanup**: `finally` block ensures proper cleanup

### Optimization Tips

1. **Memoize `getVisibleRows`**: Uses `useCallback` to avoid recalculation
   ```tsx
   const getVisibleRows = useCallback(() => {
     // Filtering and sorting logic
   }, [rows, filters, sort]);
   ```

2. **Batch state updates**: React automatically batches `setState` calls
   ```tsx
   setRows(prev => [...prev, event.data]);  // Batched by React 18+
   ```

3. **Virtual scrolling**: For 100+ rows, consider `react-virtual`
   ```tsx
   import { useVirtualizer } from '@tanstack/react-virtual';
   ```

4. **Debounce filters**: For text-based filters, debounce user input
   ```tsx
   const debouncedFilter = useMemo(
     () => debounce((value) => addFilter({ columnId: 'name', operator: 'contains', value }), 300),
     [addFilter]
   );
   ```

---

## Testing Strategy

### Integration Tests

**File**: `TabularStreamViewDemo.test.tsx`

Tests verify end-to-end functionality:

```tsx
it('should stream data and complete', async () => {
  render(<TabularStreamViewDemo />);

  // Wait for streaming to start
  await waitFor(() => {
    expect(screen.getByText(/streaming data\.\.\./i)).toBeInTheDocument();
  });

  // Wait for completion
  await waitFor(() => {
    const footer = document.querySelector('[class*="footer"]');
    expect(footer?.textContent).toMatch(/stream complete/i);
  }, { timeout: 8000 });
});
```

### Component Tests

```tsx
describe('StreamingTable', () => {
  it('renders schema headers correctly', () => {
    render(
      <StreamingTable
        schema={mockSchema}
        rows={[]}
        isStreaming={false}
        isComplete={false}
        sort={null}
      />
    );

    expect(screen.getByText('Team Member')).toBeInTheDocument();
    expect(screen.getByText('Role')).toBeInTheDocument();
  });
});
```

### Hook Tests

```tsx
describe('useTabularStream', () => {
  it('should stream rows progressively', async () => {
    const { result } = renderHook(() =>
      useTabularStream({ scenario: 'team-capacity', speed: 'fast' })
    );

    await waitFor(() => {
      expect(result.current.rows.length).toBeGreaterThan(0);
    });

    await waitFor(() => {
      expect(result.current.isComplete).toBe(true);
    }, { timeout: 5000 });
  });
});
```

---

## Accessibility

- **Keyboard navigation**: All controls (sort, filter, export) are keyboard-accessible
- **ARIA attributes**: `aria-sort` on sortable headers, `role="table"` on table
- **Screen reader support**: `aria-live="polite"` for streaming updates
- **Semantic HTML**: Proper `<table>`, `<thead>`, `<tbody>` structure
- **Focus management**: Focus preserved during streaming

---

## Pattern Variations

### Infinite Scroll Table

Stream continues indefinitely, new rows append to bottom:
```tsx
{ type: 'table_row', data: { ... } }  // No totalRows in schema
{ type: 'table_row', data: { ... } }
// ... continues forever
```

### Grouped/Hierarchical Data

Add grouping information to rows:
```tsx
{ type: 'table_row', data: { groupId: 'frontend', parentId: null, ... } }
{ type: 'table_row', data: { groupId: 'frontend', parentId: 'dev-001', ... } }
```

### Real-Time Updates

Add update events for existing rows:
```tsx
{ type: 'table_row_update', data: { rowId: 'dev-001', values: { allocation: 90 } } }
```

---

## Related Patterns

- **Chain-of-Reasoning Guide**: Streaming unstructured thinking steps
- **Agent-Await-Prompt**: Pausing mid-stream for user input
- **Multi-Turn Memory Timeline**: Managing conversation state across turns
- **Streaming Validation Loop**: Checkpoint-based validation during streaming

---

## Resources

- [React Hooks Documentation](https://react.dev/reference/react)
- [AsyncGenerator MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/AsyncGenerator)
- [CSV RFC 4180](https://www.ietf.org/rfc/rfc4180.txt)
- [Streaming Patterns Library Docs](../../README.md)

---

**Last Updated**: 2025-11-25
**Pattern Status**: ✅ Complete
**Test Coverage**: >80%
